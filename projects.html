<section class="wrapper alt style2 special" id="projects">
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Motion Planner for an Autonomous Vehicle</h2>
<p>
<!-- This project was part of my Self Driving Cars Specialization by the University of Toronto. -->
		In this project, I built a comprehensive motion planning stack for autonomous navigation, tested with the CARLA simulator, capable of avoiding static and dynamic obstacles, tracking lane center, and obeying stop signs. This involved creating a behavioral planning logic that incorporated a state machine to handle transitions between different road situations.
		Path generation was also a crucial aspect of this project, where I employed advanced mathematical techniques to generate spiral paths. This process included computing the goal state set and optimizing the path for vehicle directionality.
		To ensure safety, I devised a circle-based static collision checking mechanism that would alert the system of any potential static obstacles. This was further complemented by a path selection process that evaluated paths based on their tracking to the global path's centerline and distance from obstacles.
		The final piece of this project involved developing a velocity profile that governed the vehicle's speed according to different road scenarios and traffic rules.
		The implementation and success of this project showcased my ability to develop complex algorithms and effectively use software development tools. I am excited to continue pushing my skills to tackle more intricate challenges in the future.
</p>
</div>
<div class="image">
<img alt="Motion Planner for an Autonomous Vehicle" height="350" src="images/project_imgs/Motion_Planner_for_an_Autonomous_Vehicle.gif"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Multi Agent Tennis Using MADDPG</h2>
<p>
<!-- This project was part of my Deep Reinforcement Learning Nanodegree at Udacity. -->
		In this project, I developed a collaboration and competition algorithm to train agents in the Tennis environment. This environment involves two agents controlling rackets to keep a ball in play, with rewards given for hitting the ball over the net and penalties given for letting it hit the ground or go out of bounds.
		To achieve optimal results, I analyzed the data and developed an algorithm that allowed the agents to work collaboratively while competing against each other. I was able to create an efficient and effective algorithm that allowed the agents to achieve high scores by keeping the ball in play for extended periods.
		Throughout the project, I closely monitored the performance of the algorithm and made necessary adjustments. The goal was to achieve an average score of +0.5 over 100 consecutive episodes, and I was successful in achieving this result.
		This project allowed me to showcase my abilities as a software developer and demonstrate my ability to create effective algorithms for even the most complex environments. I am excited to tackle similar challenges in the future and continue pushing the boundaries of advanced software development.
</p>
</div>
<div class="image">
<img alt="Multi Agent Tennis Using MADDPG" height="350" src="images/project_imgs/DRLNDCollaborationAndCompetition.gif"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Continuous Control Using DDPG</h2>
<p>
<!-- This project was part of my Deep Reinforcement Learning Nanodegree at Udacity. -->
		In this project, I developed a continuous control algorithm to train an agent to maintain its position at target locations for as many time steps as possible in the Reacher environment. This environment consists of a double-jointed arm that moves to target locations, and the agent receives a reward for every step its hand is in the goal location.
		To achieve optimal results, I used distributed training with the second version of the Reacher environment that includes 20 identical agents. I developed a set of actions for the agent, consisting of a vector with four numbers corresponding to torque applicable to two joints. These actions were carefully calibrated to ensure precise movements within the environment.
		Throughout the project, I monitored the performance of the algorithm and made necessary adjustments. By leveraging distributed training and precise calibration of actions, the agent was able to maintain its position at target locations for extended periods.
		This project allowed me to showcase my abilities and further hone my skills. I am excited to tackle similar challenges in the future and continue pushing the boundaries of advanced software development.
</p>
</div>
<div class="image">
<img alt="Continuous Control Using DDPG" height="350" src="images/project_imgs/DRLNDContinuousControl.gif"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Navigation Using DQN</h2>
<p>
<!-- This project was part of my Deep Reinforcement Learning Nanodegree at Udacity. -->
		In this project, I undertook the development of a sophisticated navigation algorithm, aimed at training an agent to navigate and collect bananas in a complex, square environment. 
		With a clear understanding of the agent's objectives, I worked to develop a set of four discrete actions, including moving forward, moving backward, turning left, and turning right. Through diligent experimentation and fine-tuning of these actions, I was able to create an algorithm that allowed the agent to navigate the environment with ease, collecting yellow bananas while avoiding blue ones.
		Throughout the project, I paid close attention to the performance of the algorithm, making adjustments as necessary in order to achieve optimal results. The task was episodic in nature, with the agent required to maintain an average score of +13 over 100 consecutive episodes in order to successfully solve the environment.
		This project was an excellent opportunity to showcase my skills as a software developer, highlighting my ability to create sophisticated algorithms that achieve optimal results in complex environments. I look forward to tackling similar challenges in the future, continuing to push the boundaries of what is possible with advanced software development techniques.
</p>
</div>
<div class="image">
<img alt="Navigation Using DQN" height="350" src="images/project_imgs/DRLNDNavigation.gif"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Study of Point Features’ Selection Criteria for Efficient Outdoor SLAM</h2>
<p>
		This project was the result of my MSc Thesis at UCL.
		In this project, I developed a novel feature selection strategy for SLAM algorithms that examines low-level physical and geometric characteristics of features for selection.
		The objective was to create an algorithm for selecting a subset of observed features based on physical and geometrical merits that could adapt to sudden environmental changes using "Smart-Parameters."

		The proposed selection criteria were implemented within a state-of-the-art SLAM algorithm and evaluated using specially designed metrics.
		Results showed that using the proposed feature selection strategies, localization errors were no further than 1σ of the baseline performance, eliminating ≈ 76% of the features while building a sharper map with fewer overlapping walls, eliminating ≈ 55% features.

		This project contributes to making state-of-the-art SLAM approaches more efficient and accurate, providing a new feature selection strategy that can be applied to various SLAM architectures with potential applications in industries such as autonomous vehicles and automated warehouse robots.
</p>
</div>
<div class="image">
<img alt="Study of Point Features’ Selection Criteria for Efficient Outdoor SLAM" src="images/project_imgs/Selection_Criteria.png"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>FixiT-VR</h2>
<p>
		FixiT-VR is a 4-player game where players work together to fix broken parts of a Gameboy motherboard and assemble the parts to create a whole Gameboy.
		To play, players join a Ubiq Room and assume the colours of the corner they are in. The objects to be fixed are randomly assigned colours and each player must replace faulty parts of the same colour as their corner. Neutral objects require collaboration from multiple players. Voice communication is used to call the attention of all players to pick up and dispose of such items. The environment is a square room with an artistic texture.
		The snapping mechanism and physics of pickable objects are unique features of the game.
		Our team worked together to design the game, with Ed and I developing the code for the game functionalities and Kennedy and Abdulbaasit outlining tasks and developing/importing game objects.
</p>
</div>
<div class="image">
<img alt="FixiT-VR" src="images/project_imgs/fixit_vr_1.jpg"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>RoboCup@Home 2021 Open Platform League</h2>
<p>
		While working on my final year dissertation at the University of Leeds, I was part of the <a href="https://sensiblerobots.leeds.ac.uk/" target="blank">Sensible Robots</a> research group to develop service and assistive robot technology with high relevance for future applications, evaluated using benchmark tests in realistic, non-standardised settings.
		As part of the research group's <a href="https://sensiblerobots.leeds.ac.uk/lasr/" target="blank"> Leeds Autonomous Service Robots</a> (LASR) team, I participated in the 2021 <a href="https://athome.robocup.org/rc2021/" target="blank">RoboCup@Home</a> Open Platform League, which is an international joint project to promote AI, robotics, and related fields. It is an attempt to foster AI and intelligent robotics research by providing standard problems where a wide range of technologies can be integrated and examined.
		One of the challenges required to move objects spread around a room to their designated locations.
		In another challenge, we were required to provide a person with something from a shelf to consume when requested, avoiding obstacles while navigating.
		I worked towards tasks involving tidying up objects in the environment, depositing 5 items at their correct locations and providing a person with a requested item from a shelf while navigating avoiding small obstacles.
</p>
</div>
<div class="image">
<img alt="RoboCup@Home 2021 Open Platform League" src="images/project_imgs/robocup_team_picture.jpg"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>Pointing Based Object Recognition and Disambiguation for Autonomous Service Robots</h2>
<p>
		This project was the result of my final year dissertation at the University of Leeds.
		This project addresses the growing demand for domestic service robots that can assist humans in their daily lives, particularly in household tasks and monitoring people in need.
		The ongoing demographic shift towards an aging population and the increased acceptance of service robots due to the COVID-19 pandemic have further motivated the need for seamless and intuitive Human-Robot Interaction (HRI).
		This project combines various technologies, including Gesture Recognition, Computer Vision, Object Recognition, and Autonomous Navigation, to meet the objectives of competitions like RoboCup@Home and the goals of the Leeds Autonomous Service Robots (LASR) team.
		The primary aims of this project are to develop a robotic system capable of identifying objects pointed at in a domestic setting and disambiguating between closely placed objects by asking appropriate questions based on their attributes.
		The system should also be able to recognize and respond to multiple modes of human communication, such as speech and hand gestures.
</p>
</div>
<div class="image">
<img alt=" Pointing Based Object Recognition and Disambiguation for Autonomous Service Robots" src="images/project_imgs/Pointing_Recognition_1.png"/>
</div>
</section>
<section class="spotlight" style="display: flex; justify-content: center;">
<div class="content">
<h2>SnakeVSBlock Game in C++</h2>
<p>
		This game was developed duting my second year at the University of Leeds as part of the the Embedded Systems Project module.
		This game was programmed using advanced C++ techniques and designed to run on a K64F board of ARM mbed.
		This game features multiple programmed modes such as motion control and joystick, and includes custom-made sprites, sound, and animations.
		The code has been optimized for efficient gameplay with purpose-driven architecture, using important coding practices such as Object-Oriented Programming, version control, debugging, and Doxygen for project documentation, all following a standard coding style.
		In addition to these advanced C++ techniques, the game also employs iterative logic for choosing block numbers, adding an extra layer of complexity to the gameplay.
		The highest resolution at high speeds and smooth animations, with reaction times above your critical flicker fusion frequency, make for an immersive gaming experience.
		The game also provides the ability to control your gameplay with your preferred method, and stabilizes unwanted movement, helping to develop focus and precision.
</p>
</div>
<div class="image">
<img alt="SnakeVSBlock Game in C++" src="images/project_imgs/SvsB_1.png"/>
</div>
</section>
</section>